{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41c9c3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import pickle \n",
    "import torch as t\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab33245b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = t.load('results/llama/logistic_regression/directions_residual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2815edd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-5.4883, -6.7148, -4.4922,  ..., -6.1328, -6.7227, -6.4883],\n",
       "       device='cuda:0', dtype=torch.float16, requires_grad=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ed7d6c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def to_numpy(item):\n",
    "        if isinstance(item, torch.Tensor):\n",
    "            return item.detach().cpu().numpy()\n",
    "        elif isinstance(item, np.ndarray):\n",
    "            return item\n",
    "        elif isinstance(item, list):\n",
    "            return [to_numpy(x) for x in item]\n",
    "        else:  # scalar\n",
    "            return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8c55213a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = to_numpy(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a3e19b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-5.49 , -6.715, -4.492, ..., -6.133, -6.723, -6.49 ], dtype=float16),\n",
       " array([-4.918,  3.424, -5.633, ..., -4.402, -5.914, -6.23 ], dtype=float16),\n",
       " array([-4.387,  4.793, -6.39 , ...,  4.758, -5.426, -6.22 ], dtype=float16),\n",
       " array([-6.86 ,  3.734, -4.273, ...,  3.83 , -5.855, -6.305], dtype=float16),\n",
       " array([-5.45   , -6.074  ,  1.013  , ..., -0.10614, -1.011  , -2.691  ],\n",
       "       dtype=float16),\n",
       " array([-3.787, -3.908,  0.759, ...,  4.61 ,  1.56 , -3.348], dtype=float16),\n",
       " array([ 4.312, -5.56 ,  2.186, ...,  4.535,  0.781, -2.72 ], dtype=float16),\n",
       " array([ 1.907  , -4.773  , -0.12494, ...,  4.375  , -5.957  , -1.106  ],\n",
       "       dtype=float16),\n",
       " array([ 1.29 , -5.348,  2.643, ...,  4.69 , -4.51 , -2.762], dtype=float16),\n",
       " array([ 4.8   , -5.332 ,  4.293 , ...,  4.39  , -2.73  , -0.4587],\n",
       "       dtype=float16),\n",
       " array([ 3.922 , -5.08  ,  4.355 , ...,  2.18  , -0.4944, -0.565 ],\n",
       "       dtype=float16),\n",
       " array([ 5.207  , -3.578  ,  4.312  , ..., -0.4556 , -0.01031, -1.173  ],\n",
       "       dtype=float16),\n",
       " array([ 6.88  , -4.562 ,  4.29  , ..., -1.678 ,  1.152 , -0.6406],\n",
       "       dtype=float16),\n",
       " array([ 5.492 , -5.152 ,  0.3394, ..., -2.154 , -1.969 , -0.6724],\n",
       "       dtype=float16),\n",
       " array([ 5.418 , -5.773 , -0.8223, ..., -2.455 ,  2.068 , -1.611 ],\n",
       "       dtype=float16),\n",
       " array([ 4.945 , -5.977 , -1.851 , ..., -3.488 ,  2.63  , -0.2096],\n",
       "       dtype=float16),\n",
       " array([ 5.387, -5.953, -3.924, ..., -2.422,  2.56 , -0.338], dtype=float16),\n",
       " array([ 5.13  , -4.91  , -1.775 , ..., -2.06  ,  0.5386,  2.977 ],\n",
       "       dtype=float16),\n",
       " array([ 4.863, -4.934,  2.367, ...,  0.563,  4.215,  5.195], dtype=float16),\n",
       " array([ 4.77 , -5.59 ,  4.75 , ...,  0.873,  3.088,  4.77 ], dtype=float16),\n",
       " array([ 3.588 , -4.742 ,  2.525 , ...,  0.6055,  3.152 ,  3.996 ],\n",
       "       dtype=float16),\n",
       " array([ 2.49 , -4.21 ,  4.273, ..., -1.392,  3.248,  4.684], dtype=float16),\n",
       " array([ 0.01895, -4.184  ,  4.906  , ..., -2.1    ,  2.791  ,  3.035  ],\n",
       "       dtype=float16),\n",
       " array([ 0.2786, -4.168 ,  4.176 , ..., -3.64  ,  3.484 ,  2.357 ],\n",
       "       dtype=float16),\n",
       " array([-2.465, -4.027,  3.648, ..., -2.977,  3.62 ,  0.069], dtype=float16),\n",
       " array([-0.2195, -3.977 ,  3.76  , ..., -3.932 ,  2.662 ,  0.1243],\n",
       "       dtype=float16),\n",
       " array([-0.3525, -4.23  ,  6.25  , ..., -2.004 ,  3.71  ,  3.045 ],\n",
       "       dtype=float16),\n",
       " array([-0.8657, -4.305 ,  5.938 , ..., -4.086 ,  4.543 ,  4.594 ],\n",
       "       dtype=float16),\n",
       " array([ 0.2367, -3.895 ,  5.668 , ..., -4.24  ,  3.125 ,  4.555 ],\n",
       "       dtype=float16),\n",
       " array([-3.012, -3.744,  5.266, ..., -4.35 ,  1.085,  3.86 ], dtype=float16),\n",
       " array([-3.002 , -3.625 ,  6.36  , ..., -3.426 ,  0.5513,  0.48  ],\n",
       "       dtype=float16),\n",
       " array([-0.807 , -3.035 ,  1.353 , ..., -3.35  , -0.737 ,  0.1082],\n",
       "       dtype=float16)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ae0ebf2b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data_np \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\_tensor.py:1062\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1060\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1062\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1064\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "data_np = np.array([x.detach().cpu().numpy() if isinstance(x, t.Tensor) else x for x in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7ffbf7ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.49798966, 0.49798966, 0.49798966, ..., 0.49798966, 0.49798966,\n",
       "        0.49798966],\n",
       "       [0.49052269, 0.49798966, 0.49798966, ..., 0.49798966, 0.5066054 ,\n",
       "        0.50143596],\n",
       "       [0.49798966, 0.49798966, 0.49798966, ..., 0.49798966, 0.49798966,\n",
       "        0.49798966],\n",
       "       ...,\n",
       "       [0.49798966, 0.49798966, 0.47501436, ..., 0.69557725, 0.61458932,\n",
       "        0.62377944],\n",
       "       [0.67662263, 0.68064331, 0.65422171, ..., 0.62377944, 0.65364733,\n",
       "        0.74325101],\n",
       "       [0.65709362, 0.70476738, 0.74210224, ..., 0.75186674, 0.63871338,\n",
       "        0.74784607]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6eb9fc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logical - easy\n",
    "with open(f'data/datasets/coherence/curated_dataset_full.pkl', 'rb') as file:\n",
    "    curated_dataset = pickle.load(file)\n",
    "with open(f'data/datasets/coherence/conj_dataset.pkl', 'rb') as file:\n",
    "    conj_dataset = pickle.load(file)\n",
    "with open(f'data/datasets/coherence/neg_dataset.pkl', 'rb') as file:\n",
    "    neg_dataset = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "872d1cf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neg_common_claim_true_false.csv', 'neg_companies_true_false.csv',\n",
       "       'neg_counterfact_true_false.csv'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_dataset['filename'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f14f004c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_split(task: str, curated_dataset, probe_config, other_dataset=None, cutoff=1500):\n",
    "\n",
    "\n",
    "    if task in ['negation', 'disjunction', 'conjunction']:\n",
    "        # In this case curated dataset is the logical dataset + the remainder\n",
    "        remainder = curated_dataset[~curated_dataset['filename'].isin(['common_claim_true_false.csv', 'companies_true_false.csv', 'counterfact_true_false.csv'])]\n",
    "        curated_dataset = pd.concat([remainder, other_dataset])\n",
    "        train_set, test_set = train_test_split(curated_dataset, test_size=0.2, random_state=42, stratify=curated_dataset['filename'])\n",
    "        test_df = test_set.dropna()\n",
    "        \n",
    "    elif task == 'inference':\n",
    "        remainder = curated_dataset[~curated_dataset['filename'].isin(['common_claim_true_false.csv', 'companies_true_false.csv', 'counterfact_true_false.csv',\n",
    "                                                                      'cities.csv', 'cities_cities_conj.csv', 'cities_cities_disj.csv', 'neg_cities.csv'\n",
    "                                                                      ])]\n",
    "        curated_dataset = pd.concat([remainder, other_dataset])\n",
    "        train_set, test_set = train_test_split(curated_dataset, test_size=0.2, random_state=42, stratify=curated_dataset['filename'])\n",
    "        test_df = test_set.dropna()\n",
    "        \n",
    "\n",
    "    # Trim for batch size\n",
    "    train_set = train_set.iloc[:-(len(train_set) % probe_config), :]\n",
    "    X_clean_train = list(train_set['statement'])\n",
    "    y_clean_train = list(train_set['label'])\n",
    "    \n",
    "    return (X_clean_train, y_clean_train, test_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
